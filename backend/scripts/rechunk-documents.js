// backend/scripts/rechunk-documents.js - Fix Document Chunking Issues
const path = require('path');
require('dotenv').config({ path: path.join(__dirname, '../.env') });

const { Document, DocumentChunk } = require('../models');
const { chunkDocument } = require('../utils/documentChunker');

async function rechunkAllDocuments() {
  console.log('üîß Starting Document Rechunking Process');
  console.log('======================================');

  try {
    // Get all processed documents
    const processedDocs = await Document.findAll({
      where: { status: 'processed' },
      attributes: ['id', 'originalName', 'textContent', 'contentLength']
    });

    if (processedDocs.length === 0) {
      console.log('‚ÑπÔ∏è  No processed documents found to rechunk');
      return;
    }

    console.log(`üìÑ Found ${processedDocs.length} processed documents`);

    // Check current chunk status
    const totalChunks = await DocumentChunk.count();
    console.log(`üì¶ Current chunks in database: ${totalChunks}`);

    let rechunkedCount = 0;
    let skippedCount = 0;
    let errorCount = 0;

    for (const [index, doc] of processedDocs.entries()) {
      const progress = `[${index + 1}/${processedDocs.length}]`;
      console.log(`\n${progress} Processing: ${doc.originalName}`);

      try {
        // Check if document already has chunks
        const existingChunks = await DocumentChunk.count({
          where: { documentId: doc.id }
        });

        if (existingChunks > 0) {
          console.log(`  ‚è≠Ô∏è  Skipping (already has ${existingChunks} chunks)`);
          skippedCount++;
          continue;
        }

        // Check if document has content
        if (!doc.textContent || doc.textContent.trim().length === 0) {
          console.log(`  ‚ö†Ô∏è  Warning: No text content found`);
          errorCount++;
          continue;
        }

        console.log(`  üìä Content length: ${doc.contentLength || doc.textContent.length} characters`);

        // Rechunk the document
        const chunkResult = await chunkDocument(doc.id, doc.textContent);
        
        if (chunkResult && chunkResult.chunks && chunkResult.chunks.length > 0) {
          console.log(`  ‚úÖ Successfully created ${chunkResult.chunks.length} chunks`);
          rechunkedCount++;
        } else {
          console.log(`  ‚ùå Chunking failed - no chunks created`);
          errorCount++;
        }

      } catch (error) {
        console.log(`  ‚ùå Error: ${error.message}`);
        errorCount++;
      }

      // Add small delay to avoid overwhelming the database
      if (index < processedDocs.length - 1) {
        await new Promise(resolve => setTimeout(resolve, 100));
      }
    }

    // Final summary
    console.log('\nüìä Rechunking Summary');
    console.log('=====================');
    console.log(`Total documents processed: ${processedDocs.length}`);
    console.log(`‚úÖ Successfully rechunked: ${rechunkedCount}`);
    console.log(`‚è≠Ô∏è  Skipped (already chunked): ${skippedCount}`);
    console.log(`‚ùå Errors: ${errorCount}`);

    // Check final chunk count
    const finalChunks = await DocumentChunk.count();
    console.log(`\nüì¶ Total chunks after rechunking: ${finalChunks}`);
    console.log(`üìà Chunks added: ${finalChunks - totalChunks}`);

    if (rechunkedCount > 0) {
      console.log('\nüéâ Rechunking complete! Your RAG search should now work properly.');
      console.log('üí° Restart your server to ensure all changes take effect.');
    }

  } catch (error) {
    console.error('\nüí• Rechunking process failed:', error.message);
    console.error('Stack trace:', error.stack);
    process.exit(1);
  }
}

async function clearAllChunks() {
  console.log('üóëÔ∏è  Clearing all existing chunks...');
  
  try {
    const deletedCount = await DocumentChunk.destroy({
      where: {},
      truncate: true
    });
    
    console.log(`‚úÖ Cleared ${deletedCount} existing chunks`);
    return true;
  } catch (error) {
    console.error('‚ùå Failed to clear chunks:', error.message);
    return false;
  }
}

async function forceRechunkAll() {
  console.log('üöÄ Force Rechunking All Documents');
  console.log('=================================');
  console.log('‚ö†Ô∏è  This will delete all existing chunks and recreate them');
  
  // Clear existing chunks
  const cleared = await clearAllChunks();
  if (!cleared) {
    console.error('‚ùå Cannot proceed - failed to clear existing chunks');
    return;
  }

  // Rechunk all documents
  await rechunkAllDocuments();
}

// Command line interface
const args = process.argv.slice(2);
const command = args[0];

if (require.main === module) {
  (async () => {
    try {
      switch (command) {
        case 'force':
          await forceRechunkAll();
          break;
        case 'clear':
          await clearAllChunks();
          break;
        default:
          await rechunkAllDocuments();
          break;
      }
      
      console.log('\n‚ú® Process completed successfully');
      process.exit(0);
      
    } catch (error) {
      console.error('\nüí• Process failed:', error.message);
      process.exit(1);
    }
  })();
}

module.exports = {
  rechunkAllDocuments,
  clearAllChunks,
  forceRechunkAll
};